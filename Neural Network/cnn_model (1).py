# -*- coding: utf-8 -*-
"""CNN_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lFgtHHzbCXpaJ3sheAIow17ympBnBwRU
"""

import torch.nn as nn
import torch
from torch.autograd import Variable
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np
import time
from torch.utils.data import DataLoader

def collect_data(datapath, type, tf_idf):
    lines = []
    with open(datapath,'r',errors='ignore') as f:
        lines = f.read().splitlines()

    labels, docs = [], []
    for line in lines:
        labels.append(line.split('<fff>')[0])
        docs.append(line.split('<fff>')[-1])

    if type == 'train':
        docs = tf_idf.fit_transform(docs)
    else:
        docs = tf_idf.transform(docs)


    docs = docs.toarray()
    docs = docs.astype(np.float32)
    labels = np.array(labels, dtype=int)
    labels = torch.tensor(labels, dtype = torch.long)
    labels = Variable(labels)
    docs = Variable(torch.from_numpy(docs))
    return labels, docs

class CNN(nn.Module):
    def __init__(self, input_dim, k):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2) 
        self.relu1 = nn.ReLU()
        self.maxpool1 = nn.MaxPool1d(kernel_size=2, stride = 2)
        self.conv2 = nn.Conv1d(in_channels=16, out_channels=24, kernel_size=5, stride=1, padding=2) 
        self.relu2 = nn.ReLU()
        self.maxpool2 = nn.MaxPool1d(kernel_size=2, stride = 2)
        self.conv3 = nn.Conv1d(in_channels=24, out_channels= 32, kernel_size=5, stride=1, padding=2)
        self.relu3 = nn.ReLU()
        self.maxpool3 = nn.MaxPool1d(kernel_size=2, stride=2)
        
        self.fc1 = nn.Linear(4000, out_features=k)
        self.maxfc = nn.Softmax(dim=1)
    
    def forward(self, x):
        out = self.conv1(x)
        out = self.relu1(out)
        out = self.maxpool1(out)
        out = self.conv2(out)
        out = self.relu2(out)
        out = self.maxpool2(out)
        out = self.conv3(out)
        out = self.relu3(out)
        out = self.maxpool3(out)
        out = self.fc1(out.view(out.shape[0], -1))
        out = self.maxfc(out)
        
        return out

tf_idf = TfidfVectorizer(min_df= 6)
labels_train, docs_vector_train = collect_data('/content/train_data.txt','train', tf_idf)
labels_test, docs_vector_test = collect_data('/content/test_data.txt', 'test', tf_idf)

import sklearn
from sklearn.decomposition import TruncatedSVD

md = TruncatedSVD(n_components=1000)
md.fit(docs_vector_train)

train_svd = md.transform(docs_vector_train)

test_svd = md.transform(docs_vector_test)

train_svd, test_svd = torch.from_numpy(train_svd), torch.from_numpy(test_svd)

batch_size = 64
input_dim = train_svd.shape[1]
train = torch.utils.data.TensorDataset(train_svd, labels_train)
train_loader = torch.utils.data.DataLoader(train, shuffle=True, batch_size=batch_size)
test = torch.utils.data.TensorDataset(test_svd, labels_test)
test_loader = torch.utils.data.DataLoader(test, shuffle=True, batch_size=batch_size)

CNNmodel = CNN(input_dim, 20)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
CNNmodel.to(device)

losss = nn.CrossEntropyLoss()
lr = 0.001
optimizer = torch.optim.Adam(CNNmodel.parameters(), lr = lr)

epochs = 50
lenght = train_svd.shape[0]
count = 0
for epoch in range(epochs):
  t1 = time.time()
  correct = 0
  for(docs, labels) in train_loader:
    train = Variable(docs.view(docs.shape[0],1,docs.shape[1])).to(device)
    labels = Variable(labels).to(device)

    # print(train.shape)
    # print(labels.shape)
    # break
    optimizer.zero_grad()

    output = CNNmodel(train)

    loss = losss(output, labels)

    loss.backward()

    optimizer.step()

    count += 1
    # print(output)
    predict = torch.argmax(output.data, axis= 1)
    # print(predict)
    correct += (predict == labels).float().sum()
  t2 = time.time()
  print("Epoch: {}/{}, Accuracy: {:.6f}, Loss: {} Time: {}".format(epoch+1, epochs, correct/lenght, str(t2-t1), loss))

correct = 0
total = 0
for(docs, labels) in test_loader:
    test = Variable(docs.view(docs.shape[0],1,docs.shape[1])).to(device)
    labels = Variable(labels).to(device)
    output = CNNmodel(test)
    predict = torch.argmax(output.data, axis= 1)
    correct += (predict == labels).float().sum()
    total += len(labels)
accuracy = correct * 100. / total
print(accuracy)